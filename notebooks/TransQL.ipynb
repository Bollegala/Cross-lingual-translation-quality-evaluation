{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import MeCab\n",
    "import nltk\n",
    "import xlrd\n",
    "import string\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words in the vocabulary = 389\n"
     ]
    }
   ],
   "source": [
    "# Select all words in the data file and compute the vocabulary. \n",
    "# Write the cross-lingual word embeddings for those words to a separate file.\n",
    "# This will speed up loading word embeddings and save memory.\n",
    "\n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "vocab = set()\n",
    "for l in range(1, sheet.nrows):\n",
    "    # tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    token_ja = mecab.parse(rows[0].lower())\n",
    "    vocab = vocab.union(set(token_ja.strip().split()))\n",
    "    \n",
    "    # tokenise English texts\n",
    "    vocab = vocab.union(set(nltk.word_tokenize(rows[1].lower())))\n",
    "\n",
    "stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "add_words = ['I', 'like', 'hate', 'cat', 'cats', 'dog', 'dogs', 'banana', '好き', '嫌い', '猫', '犬', '私']\n",
    "vocab = vocab - set(stop_words)\n",
    "vocab = vocab.union(set(add_words))\n",
    "print(\"No of unique words in the vocabulary = %d\" % len(vocab))\n",
    "\n",
    "# write the vocabulary to a file for debugging purposes\n",
    "with open(\"../data/vocab.txt\", 'w') as vocab_file:\n",
    "    for word in vocab:\n",
    "        vocab_file.write(\"%s\\n\" % word)\n",
    "\n",
    "# Lets select the cross-lingual word embeddings for those words in the vocabulary.\n",
    "cross_in_embeds_fname = \"../data/ja-en.txt\"\n",
    "cross_out_embeds_fname = \"../data/ja-en.sel\"\n",
    "first_line = True\n",
    "\n",
    "with open(cross_in_embeds_fname) as cross_in:\n",
    "    with open(cross_out_embeds_fname, 'w') as cross_out:\n",
    "        for line in cross_in:\n",
    "            if first_line:\n",
    "                dim = int(line.split()[1])\n",
    "                cross_out.write(\"%d %d\\n\" % (len(vocab), dim))\n",
    "                first_line = False\n",
    "            elif line.split()[0].lower() in vocab:\n",
    "                cross_out.write(line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cross-lingual word embeddings.\n",
    "large_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.txt')\n",
    "small_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.sel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = small_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "    for ch in stop_words:\n",
    "        s = s.replace(ch, ' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd(source, target):\n",
    "    distance = embeddings.wmdistance(source, target)\n",
    "    return (distance, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mwmd(source, target):\n",
    "    # remove words that are not in the vocabulary from source and target.\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "     \n",
    "    #print(source)    \n",
    "    #print(target)\n",
    "\n",
    "    \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    # compute distances between words\n",
    "    C = np.zeros((n, m), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            first, second = embeddings[source[i]],  embeddings[target[j]]\n",
    "            first_norm, second_norm = np.linalg.norm(first), np.linalg.norm(second)\n",
    "            if first_norm > 0:\n",
    "                first = first / first_norm\n",
    "            if second_norm > 0:\n",
    "                second = second / second_norm            \n",
    "            C[i,j] = scipy.spatial.distance.euclidean(first, second)\n",
    "    \n",
    "    # Initialise variables\n",
    "    x = np.zeros(n + n*m, dtype=float)\n",
    "    T = x[n:].reshape(n,m)\n",
    "    y = x[:n]\n",
    "    \n",
    "    c = np.zeros_like(x)\n",
    "    c[:n] = 1.0\n",
    "    \n",
    "    # Inequality constraints\n",
    "    b_ub = np.zeros(n*m, dtype=float)\n",
    "    A_ub = np.zeros((n*m, n + n*m), dtype=float)    \n",
    "    for p in range(n*m):\n",
    "        for q in range(n + n*m):\n",
    "            if p % n == q:\n",
    "                A_ub[p, q % n] = -1.0\n",
    "            if (p // n) + 2 * (p % n) + n == q:\n",
    "                A_ub[p,q] = C[p % n, p // n]    \n",
    "    #print(A_ub)\n",
    "    \n",
    "    # Equality constraints \n",
    "    A_eq = np.zeros((n, n + n*m), dtype=float)\n",
    "    b_eq = np.ones(n, dtype=float)\n",
    "    #(T's columns must add to 1. See Eq. 5)\n",
    "    for p in range(n):\n",
    "        for q in range(n + m*p, n + m + m*p):\n",
    "            A_eq[p,q] = 1.0\n",
    "    \n",
    "    #print(A_eq)   \n",
    "    \n",
    "    \n",
    "    res = scipy.optimize.linprog(c, A_ub, b_ub, A_eq, b_eq, method='simplex')\n",
    "    #res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex')\n",
    "    status = {0 : \"Optimization terminated successfully\",\n",
    "              1 : \"Iteration limit reached\",\n",
    "              2 : \"Problem appears to be infeasible\",\n",
    "              3 : \"Problem appears to be unbounded\",\n",
    "              4 : \"Serious numerical difficulties encountered\"}\n",
    "    if res.status > 0:\n",
    "        print(\"\\x1b[31m %s \\x1b[0m\" % status[res.status])\n",
    "    \n",
    "    if res.status == 2:\n",
    "        # Infeasible problem. Drop equality constrains and try again.\n",
    "        res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex') \n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        return (distance_TC, 2)        \n",
    "    \n",
    "    if res.status == 0:        \n",
    "        print(\"No of iterations to optimisation = %d\" % res.nit)\n",
    "        # objective is the sum of y_i.\n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        #print(\"sum y = %f\" % distance_y)\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        #print(\"sum TC = %f\" % distance_TC)\n",
    "        return (distance_TC, res.status)\n",
    "    else:\n",
    "        return (0, res.status) \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    }
   ],
   "source": [
    "# We provide a simple UI for entering source (Japanese) and target (English) texts to compare.\n",
    "\n",
    "def Comparison(Source_Ja, Target_En):\n",
    "    source = list(set(mecab.parse(Source_Ja.lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(Target_En.lower().strip())))\n",
    "    #distance = wmd(source, target)\n",
    "    distance = mwmd(source, target)[0]\n",
    "    print(\"Semantic distance = %f\\n\" % distance)\n",
    "\n",
    "interact_manual(Comparison, Source_Ja='私は猫が好きです', Target_En=\"I like dog\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances = 30\n",
      "No of iterations to optimisation = 155\n",
      "No of iterations to optimisation = 107\n",
      "No of iterations to optimisation = 239\n",
      "No of iterations to optimisation = 398\n",
      "No of iterations to optimisation = 66\n",
      "No of iterations to optimisation = 94\n",
      "No of iterations to optimisation = 237\n",
      "No of iterations to optimisation = 255\n",
      "No of iterations to optimisation = 270\n",
      "No of iterations to optimisation = 230\n",
      "No of iterations to optimisation = 401\n",
      "No of iterations to optimisation = 248\n",
      "No of iterations to optimisation = 183\n",
      "No of iterations to optimisation = 143\n",
      "No of iterations to optimisation = 274\n",
      "No of iterations to optimisation = 321\n",
      "No of iterations to optimisation = 112\n",
      "No of iterations to optimisation = 90\n",
      "No of iterations to optimisation = 84\n",
      "No of iterations to optimisation = 170\n",
      "No of iterations to optimisation = 182\n",
      "No of iterations to optimisation = 174\n",
      "No of iterations to optimisation = 190\n",
      "No of iterations to optimisation = 106\n",
      "No of iterations to optimisation = 74\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 130\n",
      "No of iterations to optimisation = 381\n",
      "No of iterations to optimisation = 90\n",
      "No of iterations to optimisation = 365\n",
      "Failed cases = 0\n",
      "Spearman Full SpearmanrResult(correlation=0.3732325668745334, pvalue=0.042205246067081745)\n",
      "Sperman Low SpearmanrResult(correlation=-0.04488395443421177, pvalue=0.8738008002564283)\n",
      "Sperman High SpearmanrResult(correlation=0.21109157211437016, pvalue=0.4501288587473363)\n",
      "Accuracy =  36.666666666666664\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWPJERAJjyRMRCYwlT0QksP8HJE6svBrmko8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will compute the correlation between human ratings and semantic distances over all instances\n",
    "\n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "instances = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    # tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    instances.append((rows[0], rows[1], float(rows[2])))\n",
    "print(\"Total number of instances = %d\" % len(instances))\n",
    "\n",
    "# 1000 random integers between 0 and 50\n",
    "\n",
    "human_ratings = []\n",
    "distances = []\n",
    "bad_count = 0\n",
    "for x in instances:\n",
    "    source = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    #res = wmd(source, target)\n",
    "    res = mwmd(source, target)\n",
    "    if res[1] > 0:\n",
    "        bad_count += 1\n",
    "    else:\n",
    "        distances.append(res[0])\n",
    "        human_ratings.append(x[2])\n",
    "\n",
    "print(\"Failed cases = %d\" % bad_count)\n",
    "\n",
    "# convert distances to similarity and scale to [0,1]\n",
    "human_ratings = np.array(human_ratings)\n",
    "human_ratings = 1.0 - (human_ratings / np.max(human_ratings))\n",
    "distances = np.array(distances)\n",
    "distances = 1.0 - (distances / np.max(distances))\n",
    "spr = scipy.stats.spearmanr(human_ratings, distances)\n",
    "print(\"Spearman Full\", spr)\n",
    "\n",
    "# Plot linear regression line\n",
    "fit = np.polyfit(human_ratings, distances, 1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(human_ratings, fit_fn(human_ratings), '--k')\n",
    "\n",
    "sortinds = np.argsort(human_ratings)\n",
    "distances = distances[sortinds]\n",
    "human_ratings = human_ratings[sortinds]\n",
    "N = len(sortinds) // 2\n",
    "low_human, high_human = human_ratings[: N], human_ratings[N:]\n",
    "low_sim, high_sim = distances[:N], distances[N:]\n",
    "print(\"Sperman Low\", scipy.stats.spearmanr(low_human, low_sim))\n",
    "print(\"Sperman High\", scipy.stats.spearmanr(high_human, high_sim))\n",
    "\n",
    "# Compute accuracy. For low_human, predicted value must be less than or equal, \n",
    "# and for high_human predicted value must be greater than or equal to be correct.\n",
    "\n",
    "corrects = 0\n",
    "for x in low_human:\n",
    "    if fit_fn(x) <= x:\n",
    "        corrects += 1\n",
    "for x in high_human:\n",
    "    if fit_fn(x) >= x:\n",
    "        corrects += 1\n",
    "print(\"Accuracy = \", float(100 * corrects) / float(len(distances)))\n",
    "plt.plot(low_human, low_sim, 'b*', high_human, high_sim, 'r+')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
