{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import MeCab\n",
    "import nltk\n",
    "import xlrd\n",
    "import string\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words in the vocabulary = 389\n"
     ]
    }
   ],
   "source": [
    "# Select all words in the data file and compute the vocabulary. \n",
    "# Write the cross-lingual word embeddings for those words to a separate file.\n",
    "# This will speed up loading word embeddings and save memory.\n",
    "\n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "vocab = set()\n",
    "for l in range(1, sheet.nrows):\n",
    "    # tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    token_ja = mecab.parse(rows[0].lower())\n",
    "    vocab = vocab.union(set(token_ja.strip().split()))\n",
    "    \n",
    "    # tokenise English texts\n",
    "    vocab = vocab.union(set(nltk.word_tokenize(rows[1].lower())))\n",
    "\n",
    "stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "add_words = ['I', 'like', 'hate', 'cat', 'cats', 'dog', 'dogs', 'banana', '好き', '嫌い', '猫', '犬', '私']\n",
    "vocab = vocab - set(stop_words)\n",
    "vocab = vocab.union(set(add_words))\n",
    "print(\"No of unique words in the vocabulary = %d\" % len(vocab))\n",
    "\n",
    "# write the vocabulary to a file for debugging purposes\n",
    "with open(\"../data/vocab.txt\", 'w') as vocab_file:\n",
    "    for word in vocab:\n",
    "        vocab_file.write(\"%s\\n\" % word)\n",
    "\n",
    "# Lets select the cross-lingual word embeddings for those words in the vocabulary.\n",
    "cross_in_embeds_fname = \"../data/ja-en.txt\"\n",
    "cross_out_embeds_fname = \"../data/ja-en.sel\"\n",
    "first_line = True\n",
    "\n",
    "with open(cross_in_embeds_fname) as cross_in:\n",
    "    with open(cross_out_embeds_fname, 'w') as cross_out:\n",
    "        for line in cross_in:\n",
    "            if first_line:\n",
    "                dim = int(line.split()[1])\n",
    "                cross_out.write(\"%d %d\\n\" % (len(vocab), dim))\n",
    "                first_line = False\n",
    "            elif line.split()[0].lower() in vocab:\n",
    "                cross_out.write(line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cross-lingual word embeddings.\n",
    "large_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.txt')\n",
    "small_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.sel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = small_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "    for ch in stop_words:\n",
    "        s = s.replace(ch, ' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd(source, target):\n",
    "    distance = embeddings.wmdistance(source, target)\n",
    "    return (distance, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mwmd(source, target):\n",
    "    # remove words that are not in the vocabulary from source and target.\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "     \n",
    "    #print(source)    \n",
    "    #print(target)\n",
    "\n",
    "    \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    # compute distances between words\n",
    "    C = np.zeros((n, m), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            first, second = embeddings[source[i]],  embeddings[target[j]]\n",
    "            first_norm, second_norm = np.linalg.norm(first), np.linalg.norm(second)\n",
    "            if first_norm > 0:\n",
    "                first = first / first_norm\n",
    "            if second_norm > 0:\n",
    "                second = second / second_norm            \n",
    "            C[i,j] = scipy.spatial.distance.euclidean(first, second)\n",
    "    \n",
    "    # Initialise variables\n",
    "    x = np.zeros(n + n*m, dtype=float)\n",
    "    T = x[n:].reshape(n,m)\n",
    "    y = x[:n]\n",
    "    \n",
    "    c = np.zeros_like(x)\n",
    "    c[:n] = 1.0\n",
    "    \n",
    "    # Inequality constraints\n",
    "    b_ub = np.zeros(n*m, dtype=float)\n",
    "    A_ub = np.zeros((n*m, n + n*m), dtype=float)    \n",
    "    for p in range(n*m):\n",
    "        for q in range(n + n*m):\n",
    "            if p % n == q:\n",
    "                A_ub[p, q % n] = -1.0\n",
    "            if (p // n) + 2 * (p % n) + n == q:\n",
    "                A_ub[p,q] = C[p % n, p // n]    \n",
    "    #print(A_ub)\n",
    "    \n",
    "    # Equality constraints for Eq. 5 (Columns in T must be stochastic)\n",
    "    CA_eq = np.zeros((n, n + n*m), dtype=float)\n",
    "    Cb_eq = np.ones(n, dtype=float)\n",
    "    for p in range(n):\n",
    "        for q in range(n + m*p, n + m + m*p):\n",
    "            CA_eq[p,q] = 1.0\n",
    "            \n",
    "    # Equality constraints for Eq. 4 (Rows in T must be stochastic)\n",
    "    RA_eq = np.zeros((m, n + n*m), dtype=float)\n",
    "    Rb_eq = np.ones(m, dtype=float)\n",
    "    for p in range(m):\n",
    "        for q in range(n, n + n*m):\n",
    "            if p == (q - n) % m:\n",
    "                RA_eq[p,q] = 1.0\n",
    "    \n",
    "    print(RA_eq)\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "    \n",
    "    #print(A_eq)   \n",
    "    \n",
    "    \n",
    "    res = scipy.optimize.linprog(c, A_ub, b_ub, A_eq, b_eq, method='simplex')\n",
    "    #res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex')\n",
    "    status = {0 : \"Optimization terminated successfully\",\n",
    "              1 : \"Iteration limit reached\",\n",
    "              2 : \"Problem appears to be infeasible\",\n",
    "              3 : \"Problem appears to be unbounded\",\n",
    "              4 : \"Serious numerical difficulties encountered\"}\n",
    "    if res.status > 0:\n",
    "        print(\"\\x1b[31m %s \\x1b[0m\" % status[res.status])\n",
    "    \n",
    "    if res.status == 2:\n",
    "        # Infeasible problem. Drop equality constrains and try again.\n",
    "        res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex') \n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        return (distance_TC, 2)        \n",
    "    \n",
    "    if res.status == 0:        \n",
    "        print(\"No of iterations to optimisation = %d\" % res.nit)\n",
    "        # objective is the sum of y_i.\n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        #print(\"sum y = %f\" % distance_y)\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        #print(\"sum TC = %f\" % distance_TC)\n",
    "        return (distance_TC, res.status)\n",
    "    else:\n",
    "        return (0, res.status) \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    }
   ],
   "source": [
    "# We provide a simple UI for entering source (Japanese) and target (English) texts to compare.\n",
    "\n",
    "def Comparison(Source_Ja, Target_En):\n",
    "    source = list(set(mecab.parse(Source_Ja.lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(Target_En.lower().strip())))\n",
    "    #distance = wmd(source, target)\n",
    "    distance = mwmd(source, target)[0]\n",
    "    print(\"Semantic distance = %f\\n\" % distance)\n",
    "\n",
    "interact_manual(Comparison, Source_Ja='私は猫が好きです', Target_En=\"I like dog\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances = 30\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be unbounded \u001b[0m\n",
      "No of iterations to optimisation = 364\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "No of iterations to optimisation = 203\n",
      "No of iterations to optimisation = 228\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "No of iterations to optimisation = 402\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "No of iterations to optimisation = 451\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "No of iterations to optimisation = 433\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "No of iterations to optimisation = 305\n",
      "No of iterations to optimisation = 488\n",
      "No of iterations to optimisation = 345\n",
      "No of iterations to optimisation = 403\n",
      "No of iterations to optimisation = 388\n",
      "No of iterations to optimisation = 369\n",
      "No of iterations to optimisation = 255\n",
      "No of iterations to optimisation = 185\n",
      "No of iterations to optimisation = 61\n",
      "No of iterations to optimisation = 242\n",
      "\u001b[31m Problem appears to be unbounded \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "\u001b[31m Problem appears to be infeasible \u001b[0m\n",
      "Failed cases = 14\n",
      "Spearman Full SpearmanrResult(correlation=0.31075144157635665, pvalue=0.24141234938436174)\n",
      "Sperman Low SpearmanrResult(correlation=0.09639253854237599, pvalue=0.8203804112381492)\n",
      "Sperman High SpearmanrResult(correlation=0.4761904761904762, pvalue=0.23293553465009798)\n",
      "Accuracy =  18.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEBCAYAAAB7Wx7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will compute the correlation between human ratings and semantic distances over all instances\n",
    "\n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "instances = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    # tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    instances.append((rows[0], rows[1], float(rows[2])))\n",
    "print(\"Total number of instances = %d\" % len(instances))\n",
    "\n",
    "# 1000 random integers between 0 and 50\n",
    "\n",
    "human_ratings = []\n",
    "distances = []\n",
    "bad_count = 0\n",
    "for x in instances:\n",
    "    source = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    #res = wmd(source, target)\n",
    "    res = mwmd(source, target)\n",
    "    if res[1] > 0:\n",
    "        bad_count += 1\n",
    "    else:\n",
    "        distances.append(res[0])\n",
    "        human_ratings.append(x[2])\n",
    "\n",
    "print(\"Failed cases = %d\" % bad_count)\n",
    "\n",
    "# convert distances to similarity and scale to [0,1]\n",
    "human_ratings = np.array(human_ratings)\n",
    "human_ratings = 1.0 - (human_ratings / np.max(human_ratings))\n",
    "distances = np.array(distances)\n",
    "distances = 1.0 - (distances / np.max(distances))\n",
    "spr = scipy.stats.spearmanr(human_ratings, distances)\n",
    "print(\"Spearman Full\", spr)\n",
    "\n",
    "# Plot linear regression line\n",
    "fit = np.polyfit(human_ratings, distances, 1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(human_ratings, fit_fn(human_ratings), '--k')\n",
    "\n",
    "sortinds = np.argsort(human_ratings)\n",
    "distances = distances[sortinds]\n",
    "human_ratings = human_ratings[sortinds]\n",
    "N = len(sortinds) // 2\n",
    "low_human, high_human = human_ratings[: N], human_ratings[N:]\n",
    "low_sim, high_sim = distances[:N], distances[N:]\n",
    "print(\"Sperman Low\", scipy.stats.spearmanr(low_human, low_sim))\n",
    "print(\"Sperman High\", scipy.stats.spearmanr(high_human, high_sim))\n",
    "\n",
    "# Compute accuracy. For low_human, predicted value must be less than or equal, \n",
    "# and for high_human predicted value must be greater than or equal to be correct.\n",
    "\n",
    "corrects = 0\n",
    "for x in low_human:\n",
    "    if fit_fn(x) <= x:\n",
    "        corrects += 1\n",
    "for x in high_human:\n",
    "    if fit_fn(x) >= x:\n",
    "        corrects += 1\n",
    "print(\"Accuracy = \", float(100 * corrects) / float(len(distances)))\n",
    "plt.plot(low_human, low_sim, 'b*', high_human, high_sim, 'r+')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
